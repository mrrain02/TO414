---
title: "Final Project: NBA Shot Analysis"
author: "R-Hinos"
date: "2023-12-05"
output: 
  html_document: 
    highlight: tango
    theme: united
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    code_folding: show
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overarching flow of this report
1) Executive Summary
2) Motivation
3) Process
   a. Piecing Together Data Set + Reading in Data
   b. Cleaning Data Set
   c. Pre-Processing Data
   d. Splitting Train and Test
   e. Creating models
   f. Evaluating model statistics
   g. Evaluating model test with Lakers' case study
4) Explanation of R-Shiny
5) Conclusion

# Executive Summary [TO-DO at the end]


# Motivation
In Game 7 of the 2022 NBA Eastern Conference Finals, the Miami Heat were defeated by the Boston Celtics. Down 2 points with 16 seconds left in the game, the Miami Heat decided not to take a timeout and let Jimmy Butler take a shot from the left-wing of the 3-point line. Butler ended up missing the shot, and the Miami Heat ended up being eliminated from the 2022 NBA Playoffs. There were several implications that arose from Butler's missed shot. On the financial side, the Miami Heat forewent an NBA Final pool bonus of $3.20-$4.80M, NBA Final's home game ticket revenue of $42.5-$85.1M, and realized decreased ticket and apparel sales for the 2022-2023 regular season. On the non-financial standpoint, fans were scrutinizing the team, key players left in free agency, and key staff were relieved of their duties. Now imagine this scenario: the Miami Heat called a timeout, drew up a play based on a model's output that provided data regarding the highest probabilities of making a shot, executed the play, and the shot went in. To make this scenario a reality, we decided to create the NBA Shot Prediction model to equip NBA teams with a tool that can aid in drawing up plays to increase the chance a basket is scored.

# Load Libraries
```{r}
library(caret)
library(neuralnet)
library(caret)
library(class)
library(gbm)
library(kernlab)
library(C50)
library(tidyr)
library(dplyr)
library(janitor)
library(randomForest)
library(shiny)
```

## Process [TO-DO]

# 1) Piecing together a Data Set
The data set we utilized for this model contains information regarding the game, the player that made the shot, who they were being guarded by, where they took the shot, how much time was left, and much more from the 2022-2023 NBA season. We used the `nba_api` to gather the data from the 2022-2023 Season. Through this we were able to gather all shot information from the Regular Season, as well as personal information regarding each player to make our predictions more accurate. You can find the Python code used to scrape the information here `https://github.com/mrrain02/TO414.git`.

# Read Data
```{r}
# Reading in the csv that contains the data set
nba <- read.csv("2022_shot_data.csv", stringsAsFactors = TRUE)
str(nba)
summary(nba)

# Randomize the rows so all player shots are not the same
set.seed(12345)
nba <- nba[sample(nrow(nba)),]

# Since there are over 200,000 Data points, need to take smaller randomized selection 
set.seed(12345)
sample_size <- 0.1
nba <- nba[sample(1:nrow(nba), sample_size*nrow(nba)), ]

```

# 2) Cleaning Data Set [TO-DO]
Description of what we are cleaning and why we are cleaning some data

# Clean Data
```{r}
# Remove Unnecessary Columns 
nba$GRID_TYPE <- NULL
nba$GAME_ID <- NULL
nba$GAME_EVENT_ID <- NULL
nba$PLAYER_ID <- NULL
nba$PLAYER_NAME <- NULL
nba$TEAM_ID_x <- NULL
nba$EVENT_TYPE <- NULL
nba$SHOT_ATTEMPTED_FLAG <- NULL
nba$GAME_DATE <- NULL
nba$PLAYER_LAST_NAME <- NULL
nba$PLAYER_FIRST_NAME <- NULL
nba$PLAYER_SLUG <- NULL
nba$TEAM_ID_y <- NULL
nba$TEAM_SLUG <- NULL
nba$IS_DEFUNCT <- NULL
nba$TEAM_CITY <- NULL
nba$TEAM_NAME_x <- NULL
nba$TEAM_NAME_y <- NULL
nba$TEAM_ABBREVIATION <- NULL
nba$DRAFT_YEAR <- NULL
nba$DRAFT_NUMBER <- NULL
nba$STATS_TIMEFRAME <- NULL
nba$ROSTER_STATUS <- NULL

# Take Top 5 Colleges, Factorize Everything Else
nba$COLLEGE <- as.character(nba$COLLEGE)
nba$COLLEGE <- ifelse(!(nba$COLLEGE == "Kentucky" | nba$COLLEGE == "Duke" | nba$COLLEGE == "UCLA" |
nba$COLLEGE == "Arizona" | nba$COLLEGE == "Michigan"), "Other", nba$COLLEGE)
nba$COLLEGE <- as.factor(nba$COLLEGE)

# Take Top 3 Countries, Factorize Everything Else
nba$COUNTRY <- as.character(nba$COUNTRY)
nba$COUNTRY <- ifelse(!(nba$COUNTRY == "USA" | nba$COUNTRY == "Canada" | nba$COUNTRY == "Australia"), "Other", nba$COLLEGE)
nba$COUNTRY <- as.factor(nba$COUNTRY)

# Take Top 5 Heights, Factorize Everything Else 
nba$HEIGHT <- as.character(nba$HEIGHT)
nba$HEIGHT <- ifelse(!(nba$HEIGHT == "6-5" | nba$HEIGHT == "6-4" | nba$HEIGHT == "6-8" |
nba$HEIGHT == "6-6" | nba$HEIGHT == "6-7"), "Other", nba$HEIGHT)
nba$HEIGHT <- as.factor(nba$HEIGHT)


# Action Type 
nba$ACTION_TYPE <- as.character(nba$ACTION_TYPE)
nba$ACTION_TYPE <- ifelse(!(nba$ACTION_TYPE == "Jump Shot" | nba$ACTION_TYPE == "Pullup Jump shot" | nba$ACTION_TYPE == "Driving Layup Shot" |
nba$ACTION_TYPE == "Driving Floating Jump Shot" | nba$ACTION_TYPE == "Layup Shot" | nba$ACTION_TYPE == "Running Layup Shot" | nba$ACTION_TYPE == "Step Back Jump shot" | nba$ACTION_TYPE == "Driving Finger Roll Layup Shot" | nba$ACTION_TYPE == "Cutting Layup Shot" | nba$ACTION_TYPE == "Tip Layup Shot"), "Other", nba$ACTION_TYPE)
nba$ACTION_TYPE <- as.factor(nba$ACTION_TYPE)

# Some Players are Undrafted, so Undraft Round and Number Will be Set to "0" to represent that (Make them factors as well)
nba$DRAFT_ROUND[is.na(nba$DRAFT_ROUND)] <- "un_draft"
nba$DRAFT_ROUND <- as.factor(nba$DRAFT_ROUND)

# PTS, REB, AST have some NA Values. We Replace NA values with the median in each column
nba$PTS[is.na(nba$PTS)] <- median(nba$PTS, na.rm = TRUE)
nba$REB[is.na(nba$REB)] <- median(nba$REB, na.rm = TRUE)
nba$AST[is.na(nba$AST)] <- median(nba$AST, na.rm = TRUE)


# Create New Column that Shows Total Number of Years in NBA
nba$YEARS_NBA <- (nba$TO_YEAR - nba$FROM_YEAR) + 1
nba$FROM_YEAR <- NULL
nba$TO_YEAR <- NULL

nba$SHOT_MADE_FLAG <- as.factor(nba$SHOT_MADE_FLAG)

# There are some NA's (less than 90). We are just going to remove these rows
nba <- na.omit(nba)

colSums(is.na(nba))

# Some Factor Levels have "" from the Empty Strings in the Original Dataset. Need to remove these
nba$SHOT_TYPE <- droplevels(nba$SHOT_TYPE, exclude = "")
nba$SHOT_ZONE_BASIC <- droplevels(nba$SHOT_ZONE_BASIC, exclude = "")
nba$SHOT_ZONE_AREA <- droplevels(nba$SHOT_ZONE_AREA, exclude = "")
nba$SHOT_ZONE_RANGE <- droplevels(nba$SHOT_ZONE_RANGE, exclude = "")
nba$HTM <- droplevels(nba$HTM, exclude = "")
nba$VTM <- droplevels(nba$VTM, exclude = "")
str(nba)
summary(nba)

```

# 3) Pre Process Data [TO-DO]
Small description of what is happening here

# Pre-Processing Data
```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

nbamm <- as.data.frame(model.matrix(~.-1,nba))
nbamm <- clean_names(nbamm)
str(nbamm)


#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# We are going to normalize everything for KNN and ANN
nba_norm <- as.data.frame(lapply(nbamm, normalize))
summary(nba_norm)
```

# 4) Splitting Train and Test [TO-DO]
Small explanation of what the split was and why we chose it

# Split Train and Test 
```{r}

set.seed(12345)
train_set <- sample(1:nrow(nba), 0.7*nrow(nba)) 

# Split for Logistical Regression 
nba_log_train <- nba[train_set, ]
nba_log_test <- nba[-train_set, ]

# Split for ANN
nba_ann_train <- nba_norm[train_set, ]
nba_ann_test <- nba_norm[-train_set, ]


# Split for SVM
nba_svm_train <- nbamm[train_set, ]
nba_svm_test <- nbamm[-train_set, ]

#Create a train set and test set with separate x and y cols
#First the predictors - all columns except the yyes column
nba_train <- nba_norm[train_set, -match("shot_made_flag1",names(nba_norm))]
nba_test <- nba_norm[-train_set, -match("shot_made_flag1",names(nba_norm))]

#Now the response (aka Labels) - only the yyes column
nba_train_labels <- nba_norm[train_set, "shot_made_flag1"]
nba_test_labels <- nba_norm[-train_set, "shot_made_flag1"]

```

# 5) Creating Models [TO-DO]
Overview of all models created and why we chose these models to create.


## Logistical Regression 
```{r}

NbaModel=glm(SHOT_MADE_FLAG ~., data=nba_log_train,family="binomial")


Nba_StepBase = glm(SHOT_MADE_FLAG ~ PERIOD + SECONDS_REMAINING + ACTION_TYPE + SHOT_TYPE + 
    SHOT_ZONE_BASIC + SHOT_ZONE_RANGE + HTM + WEIGHT + DRAFT_ROUND + 
    YEARS_NBA + log1p(SHOT_DISTANCE) + sqrt(PTS) + sqrt(REB) + 
    sqrt(YEARS_NBA) + SHOT_TYPE:SHOT_ZONE_BASIC, data=nba_log_train,family="binomial")

# Use the logistic regression model 'NbaModel' to generate predictions on the test dataset

testpred1 <- predict(Nba_StepBase, nba_log_test, type = "response")
# Convert the predicted probabilities into binary outcomes: 1 if probability >= 0.38, otherwise 0
binpred1 <- ifelse(testpred1 >=.50, 1, 0)
# Generate a confusion matrix to evaluate the performance of t-he predictions against the actual test labels

confusionMatrix(as.factor(binpred1), as.factor(nba_log_test$SHOT_MADE_FLAG), positive = "1")

```

## Boosting (Replace ANN Model)
```{r}
# set.seed(12345)
# boost <- gbm(shot_made_flag1 ~ ., data = nba_ann_train,
#              distribution = "gaussian",
#              n.trees = 1000, shrinkage = 0.01,
#              interaction.depth = 4,
#              bag.fraction = 0.7,
#              n.minobsinnode = 5)
# saveRDS(boost, "boost.rds")
# Load the model
boost <- readRDS("boost.rds")


boost_prediction <- predict(boost, nba_ann_test)

# Display a summary of the ANN model's predictions
summary(boost_prediction)

# Convert the predicted probabilities from the ANN model into binary outcomes: 1 if probability > 0.35, otherwise 0
binary_ann <- ifelse(boost_prediction > .5, 1, 0)

# Generate a confusion matrix to evaluate the performance of the binary predictions against the actual test labels
confusionMatrix(as.factor(binary_ann), as.factor(nba_test_labels), positive = "1")

```

## KNN Model 
```{r}
set.seed(12345)
# knnpred <- knn(nba_train, nba_test, nba_train_labels, k = 150, prob=FALSE)

# (Comment) Save the model to a file
# saveRDS(knnpred, "knn_model_5.rds")
# Load the model
knn_model <- readRDS("knn_model_5.rds")

# Generate a confusion matrix using the 'caret' library to evaluate the performance of the KNN predictions ('knnpred') against the actual test labels ('tele_test_labels'). The 'positive' argument specifies that the positive class label is "1".
confusionMatrix(as.factor(knn_model), as.factor(nba_test_labels), positive="1")
```

## Decision Tree
```{r}
# nba_model <- C5.0(SHOT_MADE_FLAG ~ ., data = nba_log_train)
# plot(nba_model)

# (Comment) Save the model to a file
# saveRDS(nba_model, "tree_model.rds")
# Load the model
tree_model <- readRDS("tree_model.rds")

nba_predict <- predict(tree_model, nba_log_test)

confusionMatrix(as.factor(nba_predict), as.factor(nba_log_test$SHOT_MADE_FLAG), positive = "1")
# plot(hotel_model)

```
## Random Forest
```{r}
set.seed(12345)
# rf_model <- randomForest(x = nba_train, y = as.factor(nba_train_labels), ntree = 500)
# saveRDS(rf_model, "rf_model.rds")
# Load the model
rf_model <- readRDS("rf_model.rds")

rf_predictions <- predict(rf_model, nba_test)
confusionMatrix(as.factor(rf_predictions), as.factor(nba_test_labels), positive = "1")
```

## SVM Models 
### RBF Model 
```{r}
# m1 <- ksvm(shot_made_flag1 ~ ., data = nba_svm_train, kernel = "rbfdot")

# saveRDS(m1, "svm_rbf_model.rds")
# Load the model
svm_rbf_model <- readRDS("svm_rbf_model.rds")

# predict the values for rbfdot
p1 <- predict(svm_rbf_model, nba_svm_test)
summary(p1)

p1 <- ifelse(p1 >= 0.5, 1 , 0)


confusionMatrix(as.factor(p1),as.factor(nba_svm_test$shot_made_flag1))
```


### Poly Dot 
```{r}
# m2 <- ksvm(shot_made_flag1 ~ ., data = nba_svm_train, kernel = "rbfdot")

# saveRDS(m2, "svm_poly_model.rds")
# Load the model
svm_poly_model <- readRDS("svm_poly_model.rds")

# predict the values for rbfdot
p2 <- predict(svm_poly_model, nba_svm_test)
summary(p2)

p2 <- ifelse(p2 >= 0.5, 1 , 0)


confusionMatrix(as.factor(p2),as.factor(nba_svm_test$shot_made_flag1))

```


### laplacedot
```{r}
# m3 <- ksvm(shot_made_flag1 ~ ., data = nba_svm_train, kernel = "laplacedot")

# saveRDS(m3, "svm_ldot_model.rds")
# Load the model
svm_poly_model <- readRDS("svm_ldot_model.rds")

# predict the values for rbfdot
p3 <- predict(svm_poly_model, nba_svm_test)
summary(p3)

p3 <- ifelse(p3 >= 0.5, 1 , 0)


confusionMatrix(as.factor(p3),as.factor(nba_svm_test$shot_made_flag1))

```


```{r}
# 2-Step Decision Tree

## Combine Vectors

# Combine all the models outputs into a single data frame (for the ones that could be kept in probability, they were kept in probability format for a better decision tree)

nba_preds <- data.frame(
  log = testpred1,
  knn = as.numeric(knn_model),
  rf = rf_predictions,
  boost = boost_prediction,
  smv = p1,
  decision = nba_predict,
  true = nba_ann_test$shot_made_flag1)

head(nba_preds)
summary(nba_preds)

saveRDS(nba_preds, "nba_preds.rds")
# Load the model

```


```{r}

# Split the Data again into 70:30
set.seed(12345)
tree_rows <- sample(1:nrow(nba_preds), 0.7*nrow(nba_preds)) 

tree_test <- nba_preds[-tree_rows, ]
tree_train <- nba_preds[tree_rows, ]


# Create a new Decision Tree with the predictions of the other models 
tree_model <- C5.0(as.factor(true) ~ ., data = tree_train)

tree_predict <- predict(tree_model, tree_test)

# Look at the accuracy of the model 
confusionMatrix(as.factor(tree_predict), as.factor(tree_test$true), positive = "1")
plot(tree_model)
```


# Exmaple Test [TO-DO]
Go more in-depth on this case study 

This test goes over an example with the Lakers' Starting Lineup. It assumes infomraiton regarding the different players, the same game situation, and a location on the map. The output gives a sample

<!-- # testpred1 <- predict(Nba_StepBase, test_nba, type = "response") -->
<!-- # testpred1  -->
<!-- # # Convert the predicted probabilities into binary outcomes: 1 if probability >= 0.38, otherwise 0 -->
<!-- # binpred1 <- ifelse(testpred1 >=.50, 1, 0) -->
<!-- #  -->
<!-- # # Boost -->
<!-- # boost_prediction <- predict(boost, test_norm) -->
<!-- # # Convert the predicted probabilities from the ANN model into binary outcomes: 1 if probability > 0.35, otherwise 0 -->
<!-- # boost_prediction -->
<!-- # binary_ann <- ifelse(boost_prediction > .5, 1, 0) -->
<!-- #  -->
<!-- #  -->
<!-- # # Tree -->
<!-- # tree_model <- readRDS("tree_model.rds") -->
<!-- #  -->
<!-- # nba_predict <- predict(tree_model, test_nba) -->
<!-- # nba_predict -->
<!-- #  -->
<!-- # nba_test <- test_norm[, -match("shot_made_flag1",names(test_norm))] -->
<!-- #  -->
<!-- # # RF -->
<!-- # rf_predictions <- predict(rf_model, nba_test, type = "response") -->
<!-- # rf_predictions -->
<!-- #  -->
<!-- # #KNN Pred -->
<!-- # knnpred <- knn(nba_train, nba_test, nba_train_labels, k = 150, prob=TRUE) -->
<!-- # knnpred -->
<!-- #  -->
<!-- # #SVM -->
<!-- # p1 <- predict(svm_rbf_model, test_nbamm) -->
<!-- # p1 -->
<!-- # test_nbamm -->
<!-- #  -->


# Evaluation of Model Statistics [TO-DO]
Basically a description of the results -- talk about results of models, what it means, why we didn't reduce false positives / negatives more (whichever one Prof stated during our presentation), etc.

# Small Description of R Shiny Dashboard [TO-DO]
How to use it, etc.

# R Shiny Dashboard
```{r, echo = FALSE}
shinyAppDir("NBAGraph")
```

# Conclusion [Work in Progress]
The NBA Shot Prediction Model will change the landscape of the National Basketball Association. Teams will be able to utilize this model to increase their chances of scoring, which will prove to be vital from both the financial and non-financial standpoint. However, we understand that this one is not perfect -- and we do acknowledge these limitations associated with using the model.

One limitation associated with using this model is that there may be sampling or historical biases in the training data [EXPAND ON THIS], which can lead to inaccurate predictions. A way to mitigate this limitation is to regularly audit and update training data to ensure it remains representative of the current NBA landscape. Techniques such as data augmentation can ensure diversity in the data set. Another limitation is some factors influencing a player's ability to make a shot (e.g., mental health, injuries, playing different position than usual) is not captured by the data. 

The second limitation presents an interesting situation in which we can further increase the effectiveness of this model. In the future, we would like to incorporate data points (e.g., injuries, mental health of players) that could provide more accurate predictions. Additionally, we can incorporate more models [EXPAND ON THIS].

