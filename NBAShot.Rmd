---
title: "Final Project: NBA Shot Analysis"
author: "R-Hinos"
date: "2023-12-05"
output: 
  html_document: 
    highlight: tango
    theme: united
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Dataset Information 

We chose the NBA Shooting Data from the 2022-2023 Season that gives information on all attempted shots from the season. The dataset has information regarding the game, the player that made the shot, who they were being guarded by, where they took the shot, how much time was left, and much more. The overall goal is to create an accurate model of whether a shot will be made depending on these factors. This can have significant implications, especially in the realm of sports betting, but also for the teams to better understand trends for their team and the opponents they are playing against. It can also have implications for player contract negotiations and creating a well balanced team of players. 

# Scraping Data 

We used the `nba_api` to gather the data from the 2022-2023 Season. Through this we were able to gather all shot information from the Regular Season, as well as personal information regarding each player to make our predictions more accurate. You can find the code used to scrape the information here [ADD LINK to GITHUB].


# Load Libraries
```{r}
library(caret)
library(neuralnet)
library(caret)
library(class)
library(kernlab)
library(C50)
library(tidyr)
library(dplyr)
library(janitor)
```


# Read Data
```{r}
nba <- read.csv("2022_shot_data.csv", stringsAsFactors = TRUE)
# str(nba)
# summary(nba)
# 
# set.seed(12345)
# sample_size <- 0.1
# nba <- nba[sample(1:nrow(nba), sample_size*nrow(nba)), ]

```

# Clean Data
```{r}
# Remove Unnecessary Columns 
nba$GRID_TYPE <- NULL
nba$GAME_ID <- NULL
nba$EVENT_TYPE <- NULL
nba$GAME_EVENT_ID <- NULL
nba$PLAYER_ID <- NULL
nba$TEAM_ID_x <- NULL
nba$TEAM_ID_y <- NULL
nba$SHOT_ATTEMPTED_FLAG <- NULL
nba$GAME_DATE <- NULL
nba$PLAYER_SLUG <- NULL
nba$TEAM_SLUG <- NULL
nba$IS_DEFUNCT <- NULL
nba$TEAM_CITY <- NULL
nba$TEAM_NAME_x <- NULL
nba$TEAM_NAME_y <- NULL
nba$STATS_TIMEFRAME <- NULL
nba$DRAFT_YEAR <- NULL
nba$PLAYER_NAME <- NULL

# nba$COLLEGE <- NULL
# nba$COUNTRY <- NULL

# Some Players are Undrafted, so Undraft Round and Number Will be Set to "0" to represent that (Make them factors as well)
nba$DRAFT_ROUND[is.na(nba$DRAFT_ROUND)] <- "un_draft"
nba$DRAFT_NUMBER[is.na(nba$DRAFT_NUMBER)] <- "un_draft"
nba$DRAFT_ROUND <- as.factor(nba$DRAFT_ROUND)
nba$DRAFT_NUMBER <- as.factor(nba$DRAFT_NUMBER)

# PTS, REB, AST have some NA Values. We Replace NA values with the median in each column
nba$PTS[is.na(nba$PTS)] <- median(nba$PTS, na.rm = TRUE)
nba$REB[is.na(nba$REB)] <- median(nba$REB, na.rm = TRUE)
nba$AST[is.na(nba$AST)] <- median(nba$AST, na.rm = TRUE)


# Create New Column that Shows Total Number of Years in NBA
nba$YEARS_NBA <- (nba$TO_YEAR - nba$FROM_YEAR) + 1
nba$FROM_YEAR <- NULL
nba$TO_YEAR <- NULL


# Change Column Name to FGM 
colnames(nba)[colnames(nba) == "SHOT_MADE_FLAG"] <- "FGM"

# There are some NA's (less than 90). We are just going to remove these rows
nba <- na.omit(nba)

colSums(is.na(nba))

```

```{r}
nba <- read.csv("2022_shot_data.csv", stringsAsFactors = TRUE)

# Combine first_name and last_name into a new column 'full_name'
nba$full_name <- paste(nba$PLAYER_FIRST_NAME, nba$PLAYER_LAST_NAME, sep = " ")

# Extract unique player names and corresponding player IDs
unique_players <- unique(nba[, c("full_name", "PLAYER_ID")])

# Write the result to a new CSV file
write.csv(unique_players, "2022_player_info.csv", row.names = FALSE)
write.csv(nba, "2022_shot_data_new.csv", row.names = FALSE)

```

```


# Pre Process Data
# Pre-Processing Data
```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

nbamm <- as.data.frame(model.matrix(~.-1,nba))
nbamm <- clean_names(nbamm)
str(nbamm)


#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# We are going to normalize everything for KNN and ANN
nba_norm <- as.data.frame(lapply(nbamm, normalize))
```


# Split Train and Test 
```{r}

set.seed(12345)
train_set <- sample(1:nrow(nba), 0.7*nrow(nba)) 

# Split for Logistical Regression 
nba_log_train <- nba[train_set, ]
nba_log_test <- nba[-train_set, ]

# Split for ANN
nba_ann_train <- nba_norm[train_set, ]
nba_ann_test <- nba_norm[-train_set, ]


# Split for SVM
nba_svm_train <- nbamm[train_set, ]
nba_svm_test <- nbamm[-train_set, ]

#Create a train set and test set with separate x and y cols
#First the predictors - all columns except the yyes column
nba_train <- nba_norm[train_set, -match("FGM",names(nba_norm))]
nba_test <- nba_norm[-train_set, -match("FGM",names(nba_norm))]

#Now the response (aka Labels) - only the yyes column
nba_train_labels <- nba_norm[train_set, "FGM"]
nba_test_labels <- nba_norm[-train_set, "FGM"]


```


# Logistical Regression 
```{r}


NbaModel=glm(FGM ~., data=nba_log_train,family="binomial")

# Use the logistic regression model 'NbaModel' to generate predictions on the test dataset

testpred1 <- predict(NbaModel, nba_log_test, type = "response")
# Convert the predicted probabilities into binary outcomes: 1 if probability >= 0.38, otherwise 0
binpred1 <- ifelse(testpred1 >=.5, 1, 0)
# Generate a confusion matrix to evaluate the performance of t-he predictions against the actual test labels


confusionMatrix(as.factor(binpred1), as.factor(nba_log_test$FGM), positive = "1")

```

# ANN Model
```{r}
ann_model <- neuralnet(FGM ~., data=nba_ann_train, hidden = 3)

# (Comment) Save the model to a file
saveRDS(ann_model, "ann_model_3.rds")

# Load the model
ann_model <- readRDS("ann_model_3.rds")

ann_prediction <- predict(ann_model, nba_ann_test)

# Display a summary of the ANN model's predictions
summary(ann_prediction)

# Convert the predicted probabilities from the ANN model into binary outcomes: 1 if probability > 0.35, otherwise 0
binary_ann <- ifelse(ann_prediction > .35, 1, 0)

# Generate a confusion matrix to evaluate the performance of the binary predictions against the actual test labels
confusionMatrix(as.factor(binary_ann), as.factor(nba_test_labels), positive = "1")

```

# SVM Model
```{r}
m1 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "vanilladot")
m2 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "rbfdot")
m3 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "polydot")
m4 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "tanhdot")
m5 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "laplacedot")
m6 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "besseldot")
m7 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "anovadot")
m8 <- ksvm(FGM ~ ., data = nba_svm_train, kernel = "splinedot")

p1 <- predict(m1, nba_svm_test)
summary(p1)
p2 <- predict(m2, nba_svm_test)
summary(p2)
p3 <- predict(m3, nba_svm_test)
summary(p3)
p4 <- predict(m4, nba_svm_test)
summary(p4)
p5 <- predict(m5, nba_svm_test)
summary(p5)
p6 <- predict(m6, nba_svm_test)
summary(p6)
p7 <- predict(m7, nba_svm_test)
summary(p7)
p8 <- predict(m8, nba_svm_test)
summary(p8)

confusionMatrix(as.factor(p1),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p2),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p3),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p4),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p5),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p6),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p7),as.factor(nba_svm_test$FGM))
confusionMatrix(as.factor(p8),as.factor(nba_svm_test$FGM))

```


